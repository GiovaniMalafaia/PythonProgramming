# ğŸŒ Pipeline de ETL e Insights de CotaÃ§Ãµes de Moedas

Este projeto implementa um **pipeline de ETL (Extract, Transform, Load)** para coletar cotaÃ§Ãµes de moedas via API, transformar os dados em camadas estruturadas e carregÃ¡-los em banco de dados PostgreSQL (Neon).  
AlÃ©m disso, utiliza **LLM (ChatGPT)** para gerar **insights executivos** sobre a variaÃ§Ã£o das principais moedas.

---

## ğŸš€ Estrutura do Projeto
```text
â”œâ”€â”€ etl/
â”‚ â”œâ”€â”€ Extract.py # Extrai dados da API e salva em /raw/
â”‚ â”œâ”€â”€ Transform.py # Normaliza os dados e grava em /silver/
â”‚ â”œâ”€â”€ Load.py # Converte para Parquet e salva em /gold/
â”‚ â”œâ”€â”€ LoadPostgreSQL.py # Carrega dados para o PostgreSQL
â”‚ â”œâ”€â”€ InsightsAI.py # Gera insights executivos via LLM
â”œâ”€â”€ logs/ # Logs centralizados de execuÃ§Ã£o
â”œâ”€â”€ gold/ # Dados finais em Parquet
â”œâ”€â”€ silver/ # Dados tratados
â”œâ”€â”€ raw/ # Dados brutos da API
â”œâ”€â”€ main.py # OrquestraÃ§Ã£o do pipeline completo
â”œâ”€â”€ .env # VariÃ¡veis de ambiente (chaves, credenciais)
â””â”€â”€ README.md # Este documento
```
---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.12**
- **Bibliotecas**:  
  -  `os`, `requests`, `json`, `pandas`, `sqlalchemy`, `python-dotenv`, `logging`  
- **Banco de Dados**: PostgreSQL (Neon)  
- **LLM**: OpenAI GPT (para geraÃ§Ã£o de insights executivos)  

---

## ğŸ”„ Fluxo do Pipeline

1. **Extract** â†’ Coleta as cotaÃ§Ãµes da API e salva em `/raw/`.  
2. **Transform** â†’ Normaliza os dados (datas, moedas, taxas) e grava em `/silver/`.  
3. **Load** â†’ Converte os dados para formato Parquet e salva em `/gold/`.  
4. **LoadPostgreSQL** â†’ Carrega os dados finais no banco Neon/PostgreSQL.  
5. **InsightsAI** â†’ Utiliza ChatGPT para gerar anÃ¡lises executivas e salvar em `.txt`.  

---

## ğŸ“¥ Como baixar o projeto

Clone o repositÃ³rio com:

```bash
git clone https://github.com/GiovaniMalafaia/PythonProgramming.git
```
---

## â–¶ï¸ Como Executar

Na raiz do projeto, basta rodar:

```bash
python main.py
```

Isso executa todas as etapas do pipeline em sequÃªncia: Extract â†’ Transform â†’ Load â†’ LoadPostgreSQL â†’ InsightsAI.

Os logs sÃ£o gravados em logs/YYYY-MM-DD.log.
```

## ğŸ“Œ Objetivo AcadÃªmico

Este projeto foi desenvolvido como parte do Trabalho de Faculdade em Engenharia de Dados, com foco em:

- ProgramaÃ§Ã£o em Python;

- Boas prÃ¡ticas de ETL;

- Uso de camadas de dados (Raw, Silver, Gold);

- IntegraÃ§Ã£o com banco relacional;

- Enriquecimento de dados com InteligÃªncia Artificial (LLM).